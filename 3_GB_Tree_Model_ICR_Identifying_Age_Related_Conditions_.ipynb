{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Dansah2/Identifying_Age_Related_Conditions/blob/main/3_GB_Tree_Model_ICR_Identifying_Age_Related_Conditions_.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6NWrKiQ4fRGS"
      },
      "source": [
        "# ICR - Identifying Age-Related Conditions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tf6F6FaOB0dQ"
      },
      "source": [
        "Kaggle Dataset Download API Command:\n",
        "\n",
        "kaggle competitions download -c icr-identify-age-related-conditions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RXlEc616CFtt"
      },
      "source": [
        "Predict whether a subject has or has not been diagnosed with one of these conditions -- a binary classification problem."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aEHxmjhghVvK"
      },
      "source": [
        "##Project Outline:\n",
        "\n",
        "1) Download the dataset\n",
        "\n",
        "2) Explore/Analyze the data\n",
        "\n",
        "3) Preprocess and organize the data\n",
        "\n",
        "4) Create and Train baseline Model\n",
        "\n",
        "5) Save the Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JqdmA7kIfkiE"
      },
      "source": [
        "## Download the Dataset\n",
        "\n",
        "1) Install required libraries\n",
        "\n",
        "2) Import required libraries\n",
        "\n",
        "3) Obtain the preprocessed data previously saved to Google Drive\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "khuyKRt5FkpA"
      },
      "source": [
        "#### Install Required Libraries"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip uninstall -y keras openai jax torch protobuf typing-extensions langchain-core \\\n",
        "  google-genai fastapi jedi pandas numpy > /dev/null 2>&1"
      ],
      "metadata": {
        "id": "_IKtfWAsPps0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --quiet --upgrade \\\n",
        "  tensorflow==2.13.0 \\\n",
        "  tensorflow_decision_forests==1.5.0 \\\n",
        "  keras==2.13.1 \\\n",
        "  keras-tuner \\\n",
        "  > /dev/null 2>&1"
      ],
      "metadata": {
        "id": "Ft7TilDcXrBf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6ylR8aSxIbKf"
      },
      "source": [
        "#### Import Required Libraries"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# loading and handeling data\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# model training\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import tensorflow_decision_forests as tfdf\n",
        "\n",
        "# downloading data\n",
        "from google.colab import drive\n",
        "\n",
        "# Training/Evaluating the model\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "\n",
        "# hyperparameter tuning\n",
        "import keras_tuner as kt\n",
        "\n",
        "# graph training accuracy and loss\n",
        "import plotly.graph_objs as go\n",
        "from plotly.subplots import make_subplots"
      ],
      "metadata": {
        "id": "QVtrLcfxftWx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f3N4YRGJIrmz"
      },
      "source": [
        "#### Obtain the preprocessed data previously saved to Google Drive\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BbeUxY8jQlaw",
        "outputId": "620ac3b6-02cb-4690-b465-168a9a65d26f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "# Mount google drive to store Kaggle API for future use\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L5JLtC0lF8_I"
      },
      "outputs": [],
      "source": [
        "# create a function to read the data into a dataframe\n",
        "\n",
        "def read_function(csv_file):\n",
        "\n",
        "    return pd.read_csv(csv_file)\n",
        "\n",
        "clean_train = read_function('/content/drive/My Drive/ucla.edu_folder/ICR_Project/non_encoded_train_df.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create and Train baseline model\n",
        "1) Calculate the weights\n",
        "\n",
        "2) Create the model / callbacks\n",
        "\n",
        "3) Define the plot function\n",
        "\n",
        "4) Train the model"
      ],
      "metadata": {
        "id": "59kg4f6bjH4g"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Calculate the weights"
      ],
      "metadata": {
        "id": "d8duJCIok9o3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_weights(train_df, target):\n",
        "  # Calculate the number of samples for each label.\n",
        "  neg, pos = np.bincount(train_df[target])\n",
        "\n",
        "  # Calculate total samples.\n",
        "  total = neg + pos\n",
        "\n",
        "  # Calculate the weight for each label.\n",
        "  weight_for_0 = (1 / neg) * (total / 2.0)\n",
        "  weight_for_1 = (1 / pos) * (total / 2.0)\n",
        "\n",
        "  class_weight = {0: weight_for_0, 1: weight_for_1}\n",
        "\n",
        "  print(f'Weight for class 0: {weight_for_0:.2f}')\n",
        "  print(f'Weight for class 1: {weight_for_1:.2f}')\n",
        "\n",
        "  return class_weight\n",
        "\n",
        "class_weight = get_weights(clean_train, 'Class')"
      ],
      "metadata": {
        "id": "tcFrsdGDjIye",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "910a56bb-952a-43af-841d-135f2746d18f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Weight for class 0: 0.61\n",
            "Weight for class 1: 2.86\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Select the model"
      ],
      "metadata": {
        "id": "9q_qRRgMjKyw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Look at the models to select from\n",
        "tfdf.keras.get_all_models()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vcFKzlgAcVj7",
        "outputId": "9a2a1c8d-93e0-45ef-980f-2a1bbd415819"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[tensorflow_decision_forests.keras.RandomForestModel,\n",
              " tensorflow_decision_forests.keras.GradientBoostedTreesModel,\n",
              " tensorflow_decision_forests.keras.CartModel,\n",
              " tensorflow_decision_forests.keras.DistributedGradientBoostedTreesModel]"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# check config options\n",
        "model = tfdf.keras.GradientBoostedTreesModel(hyperparameter_template=\"benchmark_rank1\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aqgVsb3zcXoQ",
        "outputId": "33d691f1-8e5f-4aed-82bd-d68e918f7128"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Resolve hyper-parameter template \"benchmark_rank1\" to \"benchmark_rank1@v1\" -> {'growing_strategy': 'BEST_FIRST_GLOBAL', 'categorical_algorithm': 'RANDOM', 'split_axis': 'SPARSE_OBLIQUE', 'sparse_oblique_normalization': 'MIN_MAX', 'sparse_oblique_num_projections_exponent': 1.0}.\n",
            "Use /tmp/tmpunq0r_33 as temporary training directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Tune hyperparameters\n"
      ],
      "metadata": {
        "id": "E8eqqT8ZfuJy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# standardize the column names so the the tuner and the model do not print out warnings\n",
        "def sanitize_column_names(df):\n",
        "    import re\n",
        "    safe_columns = []\n",
        "    for col in df.columns:\n",
        "        # Lowercase, replace non-alphanumeric with underscore, strip trailing underscores\n",
        "        new_col = re.sub(r'\\W|^(?=\\d)', '_', col).lower().strip('_')\n",
        "        safe_columns.append(new_col)\n",
        "    df.columns = safe_columns\n",
        "    return df\n",
        "\n",
        "# Apply to your training dataframe\n",
        "clean_train = sanitize_column_names(clean_train)\n"
      ],
      "metadata": {
        "id": "ZoFAAJzygPWb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tf_dataset = tfdf.keras.pd_dataframe_to_tf_dataset(clean_train, label=\"class\")\n",
        "\n",
        "tuner = tfdf.tuner.RandomSearch(num_trials=20)\n",
        "\n",
        "# Hyper-parameters to optimize.\n",
        "tuner.choice(\"max_depth\", [3, 4, 5, 6, 7, 8, 9, 10])\n",
        "tuner.choice(\"num_trees\", [400, 500, 600, 700, 800])\n",
        "\n",
        "model = tfdf.keras.GradientBoostedTreesModel(tuner=tuner)\n",
        "model.fit(tf_dataset)\n",
        "\n",
        "print(model.summary())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gi6ClFBYub0B",
        "outputId": "d56d55d7-dcb7-4e24-e66f-c92ece243a8e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Use /tmp/tmpx28wwhbz as temporary training directory\n",
            "Reading training dataset...\n",
            "Training dataset read in 0:00:03.740821. Found 617 examples.\n",
            "Training model...\n",
            "Model trained in 0:00:07.828866\n",
            "Compiling model...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:AutoGraph could not transform <function simple_ml_inference_op_with_handle at 0x7a93e5233b00> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: could not get source code\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING: AutoGraph could not transform <function simple_ml_inference_op_with_handle at 0x7a93e5233b00> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: could not get source code\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "Model compiled.\n",
            "Model: \"gradient_boosted_trees_model_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            "=================================================================\n",
            "Total params: 1 (1.00 Byte)\n",
            "Trainable params: 0 (0.00 Byte)\n",
            "Non-trainable params: 1 (1.00 Byte)\n",
            "_________________________________________________________________\n",
            "Type: \"GRADIENT_BOOSTED_TREES\"\n",
            "Task: CLASSIFICATION\n",
            "Label: \"__LABEL\"\n",
            "\n",
            "Input Features (56):\n",
            "\tab\n",
            "\taf\n",
            "\tah\n",
            "\tam\n",
            "\tar\n",
            "\tax\n",
            "\tay\n",
            "\taz\n",
            "\tbc\n",
            "\tbd\n",
            "\tbn\n",
            "\tbp\n",
            "\tbq\n",
            "\tbr\n",
            "\tbz\n",
            "\tcb\n",
            "\tcc\n",
            "\tcd\n",
            "\tcf\n",
            "\tch\n",
            "\tcl\n",
            "\tcr\n",
            "\tcs\n",
            "\tcu\n",
            "\tcw\n",
            "\tda\n",
            "\tde\n",
            "\tdf\n",
            "\tdh\n",
            "\tdi\n",
            "\tdl\n",
            "\tdn\n",
            "\tdu\n",
            "\tdv\n",
            "\tdy\n",
            "\teb\n",
            "\tee\n",
            "\teg\n",
            "\teh\n",
            "\tej\n",
            "\tel\n",
            "\tep\n",
            "\teu\n",
            "\tfc\n",
            "\tfd\n",
            "\tfe\n",
            "\tfi\n",
            "\tfl\n",
            "\tfr\n",
            "\tfs\n",
            "\tgb\n",
            "\tge\n",
            "\tgf\n",
            "\tgh\n",
            "\tgi\n",
            "\tgl\n",
            "\n",
            "No weights\n",
            "\n",
            "Variable Importance: INV_MEAN_MIN_DEPTH:\n",
            "    1. \"du\"  0.399590 ################\n",
            "    2. \"cc\"  0.364146 ######\n",
            "    3. \"bq\"  0.360777 #####\n",
            "    4. \"gl\"  0.358786 #####\n",
            "    5. \"fr\"  0.356002 ####\n",
            "    6. \"ab\"  0.349776 ##\n",
            "    7. \"ch\"  0.349306 ##\n",
            "    8. \"eh\"  0.348681 ##\n",
            "    9. \"el\"  0.348370 ##\n",
            "   10. \"cr\"  0.347904 ##\n",
            "   11. \"cs\"  0.347439 ##\n",
            "   12. \"dl\"  0.347439 ##\n",
            "   13. \"fe\"  0.346975 ##\n",
            "   14. \"da\"  0.346667 ##\n",
            "   15. \"eu\"  0.346205 ##\n",
            "   16. \"de\"  0.345591 #\n",
            "   17. \"cu\"  0.344980 #\n",
            "   18. \"cd\"  0.344828 #\n",
            "   19. \"eb\"  0.344675 #\n",
            "   20. \"br\"  0.344371 #\n",
            "   21. \"af\"  0.344219 #\n",
            "   22. \"dh\"  0.343764 #\n",
            "   23. \"fl\"  0.343310 #\n",
            "   24. \"bc\"  0.342556 #\n",
            "   25. \"ee\"  0.342406 #\n",
            "   26. \"ah\"  0.341955 \n",
            "   27. \"ax\"  0.341955 \n",
            "   28. \"ay\"  0.341506 \n",
            "   29. \"eg\"  0.341506 \n",
            "   30. \"di\"  0.340611 \n",
            "   31. \"dy\"  0.340611 \n",
            "   32. \"dn\"  0.340166 \n",
            "   33. \"fi\"  0.340166 \n",
            "   34. \"cl\"  0.339721 \n",
            "   35. \"gh\"  0.339721 \n",
            "   36. \"am\"  0.339278 \n",
            "   37. \"df\"  0.339278 \n",
            "   38. \"dv\"  0.339278 \n",
            "   39. \"ep\"  0.339278 \n",
            "   40. \"fd\"  0.339278 \n",
            "   41. \"bp\"  0.338836 \n",
            "   42. \"cb\"  0.338836 \n",
            "   43. \"fs\"  0.338836 \n",
            "   44. \"ar\"  0.338395 \n",
            "   45. \"bn\"  0.338395 \n",
            "   46. \"cf\"  0.338395 \n",
            "   47. \"fc\"  0.338395 \n",
            "   48. \"gb\"  0.338395 \n",
            "   49. \"ge\"  0.338395 \n",
            "   50. \"gi\"  0.338395 \n",
            "\n",
            "Variable Importance: NUM_AS_ROOT:\n",
            "    1. \"du\" 26.000000 ################\n",
            "    2. \"cc\" 14.000000 ########\n",
            "    3. \"bq\" 11.000000 ######\n",
            "    4. \"gl\" 11.000000 ######\n",
            "    5. \"fr\"  7.000000 ###\n",
            "    6. \"ch\"  6.000000 ###\n",
            "    7. \"cs\"  5.000000 ##\n",
            "    8. \"el\"  5.000000 ##\n",
            "    9. \"da\"  4.000000 #\n",
            "   10. \"dl\"  4.000000 #\n",
            "   11. \"eh\"  4.000000 #\n",
            "   12. \"eu\"  4.000000 #\n",
            "   13. \"fe\"  4.000000 #\n",
            "   14. \"af\"  3.000000 #\n",
            "   15. \"cd\"  3.000000 #\n",
            "   16. \"cr\"  3.000000 #\n",
            "   17. \"eb\"  3.000000 #\n",
            "   18. \"ay\"  2.000000 \n",
            "   19. \"br\"  2.000000 \n",
            "   20. \"cu\"  2.000000 \n",
            "   21. \"dh\"  2.000000 \n",
            "   22. \"ah\"  1.000000 \n",
            "   23. \"bc\"  1.000000 \n",
            "   24. \"de\"  1.000000 \n",
            "   25. \"di\"  1.000000 \n",
            "   26. \"fl\"  1.000000 \n",
            "\n",
            "Variable Importance: NUM_NODES:\n",
            "    1. \"du\" 40.000000 ################\n",
            "    2. \"ab\" 26.000000 ##########\n",
            "    3. \"fr\" 18.000000 ######\n",
            "    4. \"cc\" 17.000000 ######\n",
            "    5. \"bq\" 15.000000 #####\n",
            "    6. \"eh\" 15.000000 #####\n",
            "    7. \"de\" 14.000000 #####\n",
            "    8. \"gl\" 14.000000 #####\n",
            "    9. \"cr\" 13.000000 ####\n",
            "   10. \"cu\" 11.000000 ####\n",
            "   11. \"ee\" 10.000000 ###\n",
            "   12. \"ax\"  9.000000 ###\n",
            "   13. \"dl\"  9.000000 ###\n",
            "   14. \"el\"  9.000000 ###\n",
            "   15. \"fl\"  9.000000 ###\n",
            "   16. \"bc\"  8.000000 ##\n",
            "   17. \"eg\"  8.000000 ##\n",
            "   18. \"fe\"  8.000000 ##\n",
            "   19. \"br\"  7.000000 ##\n",
            "   20. \"ch\"  7.000000 ##\n",
            "   21. \"da\"  7.000000 ##\n",
            "   22. \"dh\"  7.000000 ##\n",
            "   23. \"eu\"  7.000000 ##\n",
            "   24. \"ah\"  6.000000 ##\n",
            "   25. \"cd\"  6.000000 ##\n",
            "   26. \"cs\"  6.000000 ##\n",
            "   27. \"dy\"  6.000000 ##\n",
            "   28. \"eb\"  6.000000 ##\n",
            "   29. \"af\"  5.000000 #\n",
            "   30. \"dn\"  5.000000 #\n",
            "   31. \"fi\"  5.000000 #\n",
            "   32. \"cl\"  4.000000 #\n",
            "   33. \"gh\"  4.000000 #\n",
            "   34. \"am\"  3.000000 \n",
            "   35. \"df\"  3.000000 \n",
            "   36. \"di\"  3.000000 \n",
            "   37. \"dv\"  3.000000 \n",
            "   38. \"ep\"  3.000000 \n",
            "   39. \"fd\"  3.000000 \n",
            "   40. \"ay\"  2.000000 \n",
            "   41. \"bp\"  2.000000 \n",
            "   42. \"cb\"  2.000000 \n",
            "   43. \"fs\"  2.000000 \n",
            "   44. \"ar\"  1.000000 \n",
            "   45. \"bn\"  1.000000 \n",
            "   46. \"cf\"  1.000000 \n",
            "   47. \"fc\"  1.000000 \n",
            "   48. \"gb\"  1.000000 \n",
            "   49. \"ge\"  1.000000 \n",
            "   50. \"gi\"  1.000000 \n",
            "\n",
            "Variable Importance: SUM_SCORE:\n",
            "    1. \"du\" 104.083159 ################\n",
            "    2. \"cr\" 35.177587 #####\n",
            "    3. \"da\" 23.319519 ###\n",
            "    4. \"bc\" 20.128741 ###\n",
            "    5. \"ab\" 20.077489 ###\n",
            "    6. \"fr\" 18.691368 ##\n",
            "    7. \"bq\" 16.551942 ##\n",
            "    8. \"gl\" 13.142975 ##\n",
            "    9. \"eg\" 12.671529 #\n",
            "   10. \"de\" 11.542636 #\n",
            "   11. \"dy\"  9.362400 #\n",
            "   12. \"cc\"  8.530472 #\n",
            "   13. \"fe\"  6.378534 \n",
            "   14. \"dh\"  5.480423 \n",
            "   15. \"di\"  5.373887 \n",
            "   16. \"ee\"  4.813573 \n",
            "   17. \"fi\"  4.257493 \n",
            "   18. \"dl\"  4.234440 \n",
            "   19. \"el\"  3.974721 \n",
            "   20. \"cu\"  3.885214 \n",
            "   21. \"br\"  3.441306 \n",
            "   22. \"af\"  3.411499 \n",
            "   23. \"ax\"  3.167292 \n",
            "   24. \"eh\"  2.999477 \n",
            "   25. \"ep\"  2.049662 \n",
            "   26. \"fl\"  2.026640 \n",
            "   27. \"bp\"  1.597715 \n",
            "   28. \"eb\"  1.450828 \n",
            "   29. \"cs\"  1.145624 \n",
            "   30. \"ch\"  1.059090 \n",
            "   31. \"eu\"  1.013129 \n",
            "   32. \"ar\"  0.921151 \n",
            "   33. \"gh\"  0.900963 \n",
            "   34. \"dn\"  0.887159 \n",
            "   35. \"am\"  0.824771 \n",
            "   36. \"ah\"  0.785410 \n",
            "   37. \"dv\"  0.757409 \n",
            "   38. \"cl\"  0.689592 \n",
            "   39. \"df\"  0.663315 \n",
            "   40. \"cb\"  0.654942 \n",
            "   41. \"cd\"  0.649877 \n",
            "   42. \"fs\"  0.642484 \n",
            "   43. \"fd\"  0.481218 \n",
            "   44. \"ge\"  0.341816 \n",
            "   45. \"ay\"  0.335883 \n",
            "   46. \"cf\"  0.222348 \n",
            "   47. \"bn\"  0.161344 \n",
            "   48. \"fc\"  0.118714 \n",
            "   49. \"gb\"  0.072381 \n",
            "   50. \"gi\"  0.069095 \n",
            "\n",
            "\n",
            "Hyperparameter optimizer:\n",
            "\n",
            "Best parameters: max_depth:3 num_trees:700\n",
            "Num steps: 20\n",
            "Best score: -0.464162\n",
            "\n",
            "Step #0 score:-0.521382 parameters:{ max_depth:4 num_trees:800 }\n",
            "Step #1 score:-0.561363 parameters:{ max_depth:10 num_trees:500 }\n",
            "Step #2 score:-0.566997 parameters:{ max_depth:5 num_trees:600 }\n",
            "Step #3 score:-0.561363 parameters:{ max_depth:10 num_trees:800 }\n",
            "Step #4 score:-0.615057 parameters:{ max_depth:8 num_trees:800 }\n",
            "Step #5 score:-0.566997 parameters:{ max_depth:5 num_trees:400 }\n",
            "Step #6 score:-0.464162 parameters:{ max_depth:3 num_trees:700 }\n",
            "Step #7 score:-0.561363 parameters:{ max_depth:10 num_trees:600 }\n",
            "Step #8 score:-0.637759 parameters:{ max_depth:9 num_trees:500 }\n",
            "Step #9 score:-0.521382 parameters:{ max_depth:4 num_trees:700 }\n",
            "Step #10 score:-0.628501 parameters:{ max_depth:6 num_trees:700 }\n",
            "Step #11 score:-0.628501 parameters:{ max_depth:6 num_trees:600 }\n",
            "Step #12 score:-0.521382 parameters:{ max_depth:4 num_trees:500 }\n",
            "Step #13 score:-0.637759 parameters:{ max_depth:9 num_trees:400 }\n",
            "Step #14 score:-0.464162 parameters:{ max_depth:3 num_trees:400 }\n",
            "Step #15 score:-0.615057 parameters:{ max_depth:8 num_trees:400 }\n",
            "Step #16 score:-0.615057 parameters:{ max_depth:8 num_trees:700 }\n",
            "Step #17 score:-0.603777 parameters:{ max_depth:7 num_trees:800 }\n",
            "Step #18 score:-0.637759 parameters:{ max_depth:9 num_trees:800 }\n",
            "Step #19 score:-0.603777 parameters:{ max_depth:7 num_trees:700 }\n",
            "\n",
            "\n",
            "Loss: BINOMIAL_LOG_LIKELIHOOD\n",
            "Validation loss value: 0.464162\n",
            "Number of trees per iteration: 1\n",
            "Node format: NOT_SET\n",
            "Number of trees: 130\n",
            "Total number of nodes: 878\n",
            "\n",
            "Number of nodes by tree:\n",
            "Count: 130 Average: 6.75385 StdDev: 0.657051\n",
            "Min: 5 Max: 7 Ignored: 0\n",
            "----------------------------------------------\n",
            "[ 5, 6)  16  12.31%  12.31% #\n",
            "[ 6, 7)   0   0.00%  12.31%\n",
            "[ 7, 7] 114  87.69% 100.00% ##########\n",
            "\n",
            "Depth by leafs:\n",
            "Count: 504 Average: 1.96825 StdDev: 0.175323\n",
            "Min: 1 Max: 2 Ignored: 0\n",
            "----------------------------------------------\n",
            "[ 1, 2)  16   3.17%   3.17%\n",
            "[ 2, 2] 488  96.83% 100.00% ##########\n",
            "\n",
            "Number of training obs by leaf:\n",
            "Count: 504 Average: 144.444 StdDev: 163.629\n",
            "Min: 5 Max: 545 Ignored: 0\n",
            "----------------------------------------------\n",
            "[   5,  32) 185  36.71%  36.71% ##########\n",
            "[  32,  59)  68  13.49%  50.20% ####\n",
            "[  59,  86)  35   6.94%  57.14% ##\n",
            "[  86, 113)  27   5.36%  62.50% #\n",
            "[ 113, 140)  11   2.18%  64.68% #\n",
            "[ 140, 167)  23   4.56%  69.25% #\n",
            "[ 167, 194)  13   2.58%  71.83% #\n",
            "[ 194, 221)   8   1.59%  73.41%\n",
            "[ 221, 248)  11   2.18%  75.60% #\n",
            "[ 248, 275)   6   1.19%  76.79%\n",
            "[ 275, 302)   3   0.60%  77.38%\n",
            "[ 302, 329)   8   1.59%  78.97%\n",
            "[ 329, 356)  13   2.58%  81.55% #\n",
            "[ 356, 383)  15   2.98%  84.52% #\n",
            "[ 383, 410)  18   3.57%  88.10% #\n",
            "[ 410, 437)  18   3.57%  91.67% #\n",
            "[ 437, 464)   8   1.59%  93.25%\n",
            "[ 464, 491)  16   3.17%  96.43% #\n",
            "[ 491, 518)   9   1.79%  98.21%\n",
            "[ 518, 545]   9   1.79% 100.00%\n",
            "\n",
            "Attribute in nodes:\n",
            "\t40 : du [NUMERICAL]\n",
            "\t26 : ab [NUMERICAL]\n",
            "\t18 : fr [NUMERICAL]\n",
            "\t17 : cc [NUMERICAL]\n",
            "\t15 : eh [NUMERICAL]\n",
            "\t15 : bq [NUMERICAL]\n",
            "\t14 : gl [NUMERICAL]\n",
            "\t14 : de [NUMERICAL]\n",
            "\t13 : cr [NUMERICAL]\n",
            "\t11 : cu [NUMERICAL]\n",
            "\t10 : ee [NUMERICAL]\n",
            "\t9 : fl [NUMERICAL]\n",
            "\t9 : el [NUMERICAL]\n",
            "\t9 : dl [NUMERICAL]\n",
            "\t9 : ax [NUMERICAL]\n",
            "\t8 : fe [NUMERICAL]\n",
            "\t8 : eg [NUMERICAL]\n",
            "\t8 : bc [NUMERICAL]\n",
            "\t7 : eu [NUMERICAL]\n",
            "\t7 : dh [NUMERICAL]\n",
            "\t7 : da [NUMERICAL]\n",
            "\t7 : ch [NUMERICAL]\n",
            "\t7 : br [NUMERICAL]\n",
            "\t6 : eb [NUMERICAL]\n",
            "\t6 : dy [NUMERICAL]\n",
            "\t6 : cs [NUMERICAL]\n",
            "\t6 : cd [NUMERICAL]\n",
            "\t6 : ah [NUMERICAL]\n",
            "\t5 : fi [NUMERICAL]\n",
            "\t5 : dn [NUMERICAL]\n",
            "\t5 : af [NUMERICAL]\n",
            "\t4 : gh [NUMERICAL]\n",
            "\t4 : cl [NUMERICAL]\n",
            "\t3 : fd [NUMERICAL]\n",
            "\t3 : ep [NUMERICAL]\n",
            "\t3 : dv [NUMERICAL]\n",
            "\t3 : di [NUMERICAL]\n",
            "\t3 : df [NUMERICAL]\n",
            "\t3 : am [NUMERICAL]\n",
            "\t2 : fs [NUMERICAL]\n",
            "\t2 : cb [NUMERICAL]\n",
            "\t2 : bp [NUMERICAL]\n",
            "\t2 : ay [NUMERICAL]\n",
            "\t1 : gi [NUMERICAL]\n",
            "\t1 : ge [NUMERICAL]\n",
            "\t1 : gb [NUMERICAL]\n",
            "\t1 : fc [NUMERICAL]\n",
            "\t1 : cf [NUMERICAL]\n",
            "\t1 : bn [NUMERICAL]\n",
            "\t1 : ar [NUMERICAL]\n",
            "\n",
            "Attribute in nodes with depth <= 0:\n",
            "\t26 : du [NUMERICAL]\n",
            "\t14 : cc [NUMERICAL]\n",
            "\t11 : gl [NUMERICAL]\n",
            "\t11 : bq [NUMERICAL]\n",
            "\t7 : fr [NUMERICAL]\n",
            "\t6 : ch [NUMERICAL]\n",
            "\t5 : el [NUMERICAL]\n",
            "\t5 : cs [NUMERICAL]\n",
            "\t4 : fe [NUMERICAL]\n",
            "\t4 : eu [NUMERICAL]\n",
            "\t4 : eh [NUMERICAL]\n",
            "\t4 : dl [NUMERICAL]\n",
            "\t4 : da [NUMERICAL]\n",
            "\t3 : eb [NUMERICAL]\n",
            "\t3 : cr [NUMERICAL]\n",
            "\t3 : cd [NUMERICAL]\n",
            "\t3 : af [NUMERICAL]\n",
            "\t2 : dh [NUMERICAL]\n",
            "\t2 : cu [NUMERICAL]\n",
            "\t2 : br [NUMERICAL]\n",
            "\t2 : ay [NUMERICAL]\n",
            "\t1 : fl [NUMERICAL]\n",
            "\t1 : di [NUMERICAL]\n",
            "\t1 : de [NUMERICAL]\n",
            "\t1 : bc [NUMERICAL]\n",
            "\t1 : ah [NUMERICAL]\n",
            "\n",
            "Attribute in nodes with depth <= 1:\n",
            "\t40 : du [NUMERICAL]\n",
            "\t26 : ab [NUMERICAL]\n",
            "\t18 : fr [NUMERICAL]\n",
            "\t17 : cc [NUMERICAL]\n",
            "\t15 : eh [NUMERICAL]\n",
            "\t15 : bq [NUMERICAL]\n",
            "\t14 : gl [NUMERICAL]\n",
            "\t14 : de [NUMERICAL]\n",
            "\t13 : cr [NUMERICAL]\n",
            "\t11 : cu [NUMERICAL]\n",
            "\t10 : ee [NUMERICAL]\n",
            "\t9 : fl [NUMERICAL]\n",
            "\t9 : el [NUMERICAL]\n",
            "\t9 : dl [NUMERICAL]\n",
            "\t9 : ax [NUMERICAL]\n",
            "\t8 : fe [NUMERICAL]\n",
            "\t8 : eg [NUMERICAL]\n",
            "\t8 : bc [NUMERICAL]\n",
            "\t7 : eu [NUMERICAL]\n",
            "\t7 : dh [NUMERICAL]\n",
            "\t7 : da [NUMERICAL]\n",
            "\t7 : ch [NUMERICAL]\n",
            "\t7 : br [NUMERICAL]\n",
            "\t6 : eb [NUMERICAL]\n",
            "\t6 : dy [NUMERICAL]\n",
            "\t6 : cs [NUMERICAL]\n",
            "\t6 : cd [NUMERICAL]\n",
            "\t6 : ah [NUMERICAL]\n",
            "\t5 : fi [NUMERICAL]\n",
            "\t5 : dn [NUMERICAL]\n",
            "\t5 : af [NUMERICAL]\n",
            "\t4 : gh [NUMERICAL]\n",
            "\t4 : cl [NUMERICAL]\n",
            "\t3 : fd [NUMERICAL]\n",
            "\t3 : ep [NUMERICAL]\n",
            "\t3 : dv [NUMERICAL]\n",
            "\t3 : di [NUMERICAL]\n",
            "\t3 : df [NUMERICAL]\n",
            "\t3 : am [NUMERICAL]\n",
            "\t2 : fs [NUMERICAL]\n",
            "\t2 : cb [NUMERICAL]\n",
            "\t2 : bp [NUMERICAL]\n",
            "\t2 : ay [NUMERICAL]\n",
            "\t1 : gi [NUMERICAL]\n",
            "\t1 : ge [NUMERICAL]\n",
            "\t1 : gb [NUMERICAL]\n",
            "\t1 : fc [NUMERICAL]\n",
            "\t1 : cf [NUMERICAL]\n",
            "\t1 : bn [NUMERICAL]\n",
            "\t1 : ar [NUMERICAL]\n",
            "\n",
            "Attribute in nodes with depth <= 2:\n",
            "\t40 : du [NUMERICAL]\n",
            "\t26 : ab [NUMERICAL]\n",
            "\t18 : fr [NUMERICAL]\n",
            "\t17 : cc [NUMERICAL]\n",
            "\t15 : eh [NUMERICAL]\n",
            "\t15 : bq [NUMERICAL]\n",
            "\t14 : gl [NUMERICAL]\n",
            "\t14 : de [NUMERICAL]\n",
            "\t13 : cr [NUMERICAL]\n",
            "\t11 : cu [NUMERICAL]\n",
            "\t10 : ee [NUMERICAL]\n",
            "\t9 : fl [NUMERICAL]\n",
            "\t9 : el [NUMERICAL]\n",
            "\t9 : dl [NUMERICAL]\n",
            "\t9 : ax [NUMERICAL]\n",
            "\t8 : fe [NUMERICAL]\n",
            "\t8 : eg [NUMERICAL]\n",
            "\t8 : bc [NUMERICAL]\n",
            "\t7 : eu [NUMERICAL]\n",
            "\t7 : dh [NUMERICAL]\n",
            "\t7 : da [NUMERICAL]\n",
            "\t7 : ch [NUMERICAL]\n",
            "\t7 : br [NUMERICAL]\n",
            "\t6 : eb [NUMERICAL]\n",
            "\t6 : dy [NUMERICAL]\n",
            "\t6 : cs [NUMERICAL]\n",
            "\t6 : cd [NUMERICAL]\n",
            "\t6 : ah [NUMERICAL]\n",
            "\t5 : fi [NUMERICAL]\n",
            "\t5 : dn [NUMERICAL]\n",
            "\t5 : af [NUMERICAL]\n",
            "\t4 : gh [NUMERICAL]\n",
            "\t4 : cl [NUMERICAL]\n",
            "\t3 : fd [NUMERICAL]\n",
            "\t3 : ep [NUMERICAL]\n",
            "\t3 : dv [NUMERICAL]\n",
            "\t3 : di [NUMERICAL]\n",
            "\t3 : df [NUMERICAL]\n",
            "\t3 : am [NUMERICAL]\n",
            "\t2 : fs [NUMERICAL]\n",
            "\t2 : cb [NUMERICAL]\n",
            "\t2 : bp [NUMERICAL]\n",
            "\t2 : ay [NUMERICAL]\n",
            "\t1 : gi [NUMERICAL]\n",
            "\t1 : ge [NUMERICAL]\n",
            "\t1 : gb [NUMERICAL]\n",
            "\t1 : fc [NUMERICAL]\n",
            "\t1 : cf [NUMERICAL]\n",
            "\t1 : bn [NUMERICAL]\n",
            "\t1 : ar [NUMERICAL]\n",
            "\n",
            "Attribute in nodes with depth <= 3:\n",
            "\t40 : du [NUMERICAL]\n",
            "\t26 : ab [NUMERICAL]\n",
            "\t18 : fr [NUMERICAL]\n",
            "\t17 : cc [NUMERICAL]\n",
            "\t15 : eh [NUMERICAL]\n",
            "\t15 : bq [NUMERICAL]\n",
            "\t14 : gl [NUMERICAL]\n",
            "\t14 : de [NUMERICAL]\n",
            "\t13 : cr [NUMERICAL]\n",
            "\t11 : cu [NUMERICAL]\n",
            "\t10 : ee [NUMERICAL]\n",
            "\t9 : fl [NUMERICAL]\n",
            "\t9 : el [NUMERICAL]\n",
            "\t9 : dl [NUMERICAL]\n",
            "\t9 : ax [NUMERICAL]\n",
            "\t8 : fe [NUMERICAL]\n",
            "\t8 : eg [NUMERICAL]\n",
            "\t8 : bc [NUMERICAL]\n",
            "\t7 : eu [NUMERICAL]\n",
            "\t7 : dh [NUMERICAL]\n",
            "\t7 : da [NUMERICAL]\n",
            "\t7 : ch [NUMERICAL]\n",
            "\t7 : br [NUMERICAL]\n",
            "\t6 : eb [NUMERICAL]\n",
            "\t6 : dy [NUMERICAL]\n",
            "\t6 : cs [NUMERICAL]\n",
            "\t6 : cd [NUMERICAL]\n",
            "\t6 : ah [NUMERICAL]\n",
            "\t5 : fi [NUMERICAL]\n",
            "\t5 : dn [NUMERICAL]\n",
            "\t5 : af [NUMERICAL]\n",
            "\t4 : gh [NUMERICAL]\n",
            "\t4 : cl [NUMERICAL]\n",
            "\t3 : fd [NUMERICAL]\n",
            "\t3 : ep [NUMERICAL]\n",
            "\t3 : dv [NUMERICAL]\n",
            "\t3 : di [NUMERICAL]\n",
            "\t3 : df [NUMERICAL]\n",
            "\t3 : am [NUMERICAL]\n",
            "\t2 : fs [NUMERICAL]\n",
            "\t2 : cb [NUMERICAL]\n",
            "\t2 : bp [NUMERICAL]\n",
            "\t2 : ay [NUMERICAL]\n",
            "\t1 : gi [NUMERICAL]\n",
            "\t1 : ge [NUMERICAL]\n",
            "\t1 : gb [NUMERICAL]\n",
            "\t1 : fc [NUMERICAL]\n",
            "\t1 : cf [NUMERICAL]\n",
            "\t1 : bn [NUMERICAL]\n",
            "\t1 : ar [NUMERICAL]\n",
            "\n",
            "Attribute in nodes with depth <= 5:\n",
            "\t40 : du [NUMERICAL]\n",
            "\t26 : ab [NUMERICAL]\n",
            "\t18 : fr [NUMERICAL]\n",
            "\t17 : cc [NUMERICAL]\n",
            "\t15 : eh [NUMERICAL]\n",
            "\t15 : bq [NUMERICAL]\n",
            "\t14 : gl [NUMERICAL]\n",
            "\t14 : de [NUMERICAL]\n",
            "\t13 : cr [NUMERICAL]\n",
            "\t11 : cu [NUMERICAL]\n",
            "\t10 : ee [NUMERICAL]\n",
            "\t9 : fl [NUMERICAL]\n",
            "\t9 : el [NUMERICAL]\n",
            "\t9 : dl [NUMERICAL]\n",
            "\t9 : ax [NUMERICAL]\n",
            "\t8 : fe [NUMERICAL]\n",
            "\t8 : eg [NUMERICAL]\n",
            "\t8 : bc [NUMERICAL]\n",
            "\t7 : eu [NUMERICAL]\n",
            "\t7 : dh [NUMERICAL]\n",
            "\t7 : da [NUMERICAL]\n",
            "\t7 : ch [NUMERICAL]\n",
            "\t7 : br [NUMERICAL]\n",
            "\t6 : eb [NUMERICAL]\n",
            "\t6 : dy [NUMERICAL]\n",
            "\t6 : cs [NUMERICAL]\n",
            "\t6 : cd [NUMERICAL]\n",
            "\t6 : ah [NUMERICAL]\n",
            "\t5 : fi [NUMERICAL]\n",
            "\t5 : dn [NUMERICAL]\n",
            "\t5 : af [NUMERICAL]\n",
            "\t4 : gh [NUMERICAL]\n",
            "\t4 : cl [NUMERICAL]\n",
            "\t3 : fd [NUMERICAL]\n",
            "\t3 : ep [NUMERICAL]\n",
            "\t3 : dv [NUMERICAL]\n",
            "\t3 : di [NUMERICAL]\n",
            "\t3 : df [NUMERICAL]\n",
            "\t3 : am [NUMERICAL]\n",
            "\t2 : fs [NUMERICAL]\n",
            "\t2 : cb [NUMERICAL]\n",
            "\t2 : bp [NUMERICAL]\n",
            "\t2 : ay [NUMERICAL]\n",
            "\t1 : gi [NUMERICAL]\n",
            "\t1 : ge [NUMERICAL]\n",
            "\t1 : gb [NUMERICAL]\n",
            "\t1 : fc [NUMERICAL]\n",
            "\t1 : cf [NUMERICAL]\n",
            "\t1 : bn [NUMERICAL]\n",
            "\t1 : ar [NUMERICAL]\n",
            "\n",
            "Condition type in nodes:\n",
            "\t374 : HigherCondition\n",
            "Condition type in nodes with depth <= 0:\n",
            "\t130 : HigherCondition\n",
            "Condition type in nodes with depth <= 1:\n",
            "\t374 : HigherCondition\n",
            "Condition type in nodes with depth <= 2:\n",
            "\t374 : HigherCondition\n",
            "Condition type in nodes with depth <= 3:\n",
            "\t374 : HigherCondition\n",
            "Condition type in nodes with depth <= 5:\n",
            "\t374 : HigherCondition\n",
            "\n",
            "Training logs:\n",
            "Number of iteration to final model: 130\n",
            "\tIter:1 train-loss:0.854250 valid-loss:0.833704  train-accuracy:0.823214 valid-accuracy:0.842105\n",
            "\tIter:2 train-loss:0.794809 valid-loss:0.797670  train-accuracy:0.823214 valid-accuracy:0.842105\n",
            "\tIter:3 train-loss:0.749318 valid-loss:0.762543  train-accuracy:0.823214 valid-accuracy:0.842105\n",
            "\tIter:4 train-loss:0.714176 valid-loss:0.743258  train-accuracy:0.823214 valid-accuracy:0.842105\n",
            "\tIter:5 train-loss:0.680427 valid-loss:0.713925  train-accuracy:0.823214 valid-accuracy:0.842105\n",
            "\tIter:6 train-loss:0.649487 valid-loss:0.682638  train-accuracy:0.851786 valid-accuracy:0.859649\n",
            "\tIter:16 train-loss:0.466892 valid-loss:0.596601  train-accuracy:0.933929 valid-accuracy:0.877193\n",
            "\tIter:26 train-loss:0.377456 valid-loss:0.590215  train-accuracy:0.953571 valid-accuracy:0.859649\n",
            "\tIter:36 train-loss:0.315939 valid-loss:0.565237  train-accuracy:0.964286 valid-accuracy:0.859649\n",
            "\tIter:46 train-loss:0.263968 valid-loss:0.557920  train-accuracy:0.969643 valid-accuracy:0.859649\n",
            "\tIter:56 train-loss:0.229165 valid-loss:0.541964  train-accuracy:0.975000 valid-accuracy:0.859649\n",
            "\tIter:66 train-loss:0.202645 valid-loss:0.523548  train-accuracy:0.978571 valid-accuracy:0.859649\n",
            "\tIter:76 train-loss:0.175469 valid-loss:0.528234  train-accuracy:0.982143 valid-accuracy:0.859649\n",
            "\tIter:86 train-loss:0.150488 valid-loss:0.504039  train-accuracy:0.989286 valid-accuracy:0.859649\n",
            "\tIter:96 train-loss:0.130010 valid-loss:0.490322  train-accuracy:0.992857 valid-accuracy:0.859649\n",
            "\tIter:106 train-loss:0.114961 valid-loss:0.487844  train-accuracy:0.994643 valid-accuracy:0.859649\n",
            "\tIter:116 train-loss:0.102846 valid-loss:0.475622  train-accuracy:0.996429 valid-accuracy:0.859649\n",
            "\tIter:126 train-loss:0.089917 valid-loss:0.469268  train-accuracy:0.996429 valid-accuracy:0.877193\n",
            "\tIter:136 train-loss:0.081898 valid-loss:0.464954  train-accuracy:0.996429 valid-accuracy:0.859649\n",
            "\tIter:146 train-loss:0.072915 valid-loss:0.479952  train-accuracy:0.998214 valid-accuracy:0.859649\n",
            "\tIter:156 train-loss:0.064986 valid-loss:0.476820  train-accuracy:0.998214 valid-accuracy:0.859649\n",
            "\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Train the model"
      ],
      "metadata": {
        "id": "z8zaWGPTlDU8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create list of ids for the creation of oof dataframe.\n",
        "ID_LIST = clean_train.index\n",
        "\n",
        "# Create a dataframe of required size with zero values.\n",
        "oof = pd.DataFrame(data=np.zeros((len(ID_LIST),1)), index=ID_LIST)\n",
        "\n",
        "# Create an empty dictionary to store the models trained for each fold.\n",
        "models = {}\n",
        "\n",
        "# Create empty dict to save metircs for the models trained for each fold.\n",
        "accuracy = {}\n",
        "cross_entropy = {}\n",
        "\n",
        "# Save the name of the label column to a variable.\n",
        "label = \"class\"\n",
        "\n",
        "# Creates a GroupKFold with 5 splits\n",
        "kf = KFold(n_splits=5)"
      ],
      "metadata": {
        "id": "ctmUQYwZnjA9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_model(dataset_df, class_weight):\n",
        "  # Create subplots for accuracy and loss\n",
        "  fig = make_subplots(rows=5, cols=1, subplot_titles=(\"Accuracy\", \"Loss\", \"Precision\", \"Recall\", \"F1-Score\"))\n",
        "\n",
        "  # initialize evaluation metrics\n",
        "  precision_scores = []\n",
        "  recall_scores = []\n",
        "  f1_scores = []\n",
        "  average_loss = 0\n",
        "  average_acc = 0\n",
        "\n",
        "  # Loop through each fold\n",
        "  for i, (train_index, valid_index) in enumerate(kf.split(X=dataset_df)):\n",
        "    print('##### Fold',i+1)\n",
        "\n",
        "    # Fetch values corresponding to the index\n",
        "    train_df = dataset_df.iloc[train_index]\n",
        "    valid_df = dataset_df.iloc[valid_index]\n",
        "    valid_ids = valid_df.index.values\n",
        "\n",
        "    train_ds = tfdf.keras.pd_dataframe_to_tf_dataset(train_df, label=label)\n",
        "    valid_ds = tfdf.keras.pd_dataframe_to_tf_dataset(valid_df, label=label)\n",
        "\n",
        "    # Define the model and metrics\n",
        "    model = tfdf.keras.GradientBoostedTreesModel(max_depth=3, num_trees=700)\n",
        "    model.compile(metrics=[\"accuracy\", \"binary_crossentropy\"])\n",
        "\n",
        "    # Train the model\n",
        "    model.fit(x=train_ds, class_weight=class_weight)\n",
        "\n",
        "    # Store the model\n",
        "    models[f\"fold_{i+1}\"] = model\n",
        "\n",
        "    # Predict OOF value for validation data\n",
        "    predict = model.predict(x=valid_ds)\n",
        "\n",
        "    # Store the predictions in oof dataframe\n",
        "    oof.loc[valid_ids, 0] = predict.flatten()\n",
        "\n",
        "    # Calculate precision, recall, and F1-score\n",
        "    precision_fold = precision_score(valid_df[label], (predict > 0.5).astype(int))\n",
        "    recall_fold = recall_score(valid_df[label], (predict > 0.5).astype(int))\n",
        "    f1_fold = f1_score(valid_df[label], (predict > 0.5).astype(int))\n",
        "\n",
        "    # Append the values to the respective lists\n",
        "    precision_scores.append(precision_fold)\n",
        "    recall_scores.append(recall_fold)\n",
        "    f1_scores.append(f1_fold)\n",
        "\n",
        "    # Evaluate and store the metrics in respective dicts\n",
        "    evaluation = model.evaluate(x=valid_ds,return_dict=True)\n",
        "    accuracy[f\"fold_{i+1}\"] = evaluation[\"accuracy\"]\n",
        "    cross_entropy[f\"fold_{i+1}\"]= evaluation[\"binary_crossentropy\"]\n",
        "\n",
        "    # Update accuracy plot\n",
        "    fold_accuracy = evaluation[\"accuracy\"]\n",
        "    fig.add_trace(go.Scatter(x=[i+1], y=[fold_accuracy], mode='markers+lines', name=f'Accuracy Fold {i+1}'), row=1, col=1)\n",
        "\n",
        "    # Update loss plot\n",
        "    fold_loss = evaluation[\"binary_crossentropy\"]\n",
        "    fig.add_trace(go.Scatter(x=[i+1], y=[fold_loss], mode='markers+lines', name=f'Loss Fold {i+1}'), row=2, col=1)\n",
        "\n",
        "    # Update precision plot\n",
        "    fig.add_trace(go.Scatter(x=[i+1], y=[precision_fold], mode='markers+lines', name=f'Precision Fold {i+1}'), row=3, col=1)\n",
        "\n",
        "    # Update recall plot\n",
        "    fig.add_trace(go.Scatter(x=[i+1], y=[recall_fold], mode='markers+lines', name=f'Recall Fold {i+1}'), row=4, col=1)\n",
        "\n",
        "    # Update f1-score plot\n",
        "    fig.add_trace(go.Scatter(x=[i+1], y=[f1_fold], mode='markers+lines', name=f'F1-Score Fold {i+1}'), row=5, col=1)\n",
        "\n",
        "  # calculate / print eval metrics\n",
        "  for _model in  models:\n",
        "    average_loss += cross_entropy[_model]\n",
        "    average_acc += accuracy[_model]\n",
        "    print(f\"\\n{_model}: acc: {accuracy[_model]:.4f} loss: {cross_entropy[_model]:.4f}\")\n",
        "\n",
        "  print(f\"\\nAverage accuracy: {average_acc/5:.4f}  Average loss: {average_loss/5:.4f}\\n\")\n",
        "\n",
        "  for i in range(len(models)):\n",
        "    print(f\"\\nPrecison: {precision_scores[i]:.4f}, Recall: {recall_scores[i]:.4f}, F1 Score: {f1_scores[i]:.4f}\")\n",
        "\n",
        "  print(f\"\\nAverage Precision: {np.mean(precision_scores):.4f}  Average Recall: {np.mean(recall_scores):.4f}, Average F1 Score: {np.mean(f1_scores):.4f}\")\n",
        "\n",
        "  # Set titles for both subplots\n",
        "  fig.update_layout(title=\"Evaluation Metrics per Fold\")\n",
        "  fig.update_yaxes(title_text=\"Value\", row=3, col=1)\n",
        "  fig.update_xaxes(title_text=\"Fold\", row=5, col=1)\n",
        "\n",
        "  fig.show()\n",
        "\n",
        "  return model\n",
        "\n",
        "model = train_model(clean_train, class_weight)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "-NNr8BbtaeIx",
        "outputId": "95273bb9-c4ab-4608-d358-5554871a6b5e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "##### Fold 1\n",
            "Use /tmp/tmp6xq2zy2r as temporary training directory\n",
            "Reading training dataset...\n",
            "Training dataset read in 0:00:00.755691. Found 493 examples.\n",
            "Training model...\n",
            "Model trained in 0:00:00.423440\n",
            "Compiling model...\n",
            "Model compiled.\n",
            "1/1 [==============================] - 0s 112ms/step\n",
            "1/1 [==============================] - 1s 513ms/step - loss: 0.0000e+00 - accuracy: 0.9597 - binary_crossentropy: 0.1458\n",
            "##### Fold 2\n",
            "Use /tmp/tmp8s0lw809 as temporary training directory\n",
            "Reading training dataset...\n",
            "Training dataset read in 0:00:00.723573. Found 493 examples.\n",
            "Training model...\n",
            "Model trained in 0:00:00.344263\n",
            "Compiling model...\n",
            "Model compiled.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:5 out of the last 5 calls to <function InferenceCoreModel.make_predict_function.<locals>.predict_function_trained at 0x7a9375293ec0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 95ms/step\n",
            "1/1 [==============================] - 0s 285ms/step - loss: 0.0000e+00 - accuracy: 0.8790 - binary_crossentropy: 0.2566\n",
            "##### Fold 3\n",
            "Use /tmp/tmpg_k3xfq7 as temporary training directory\n",
            "Reading training dataset...\n",
            "Training dataset read in 0:00:00.773492. Found 494 examples.\n",
            "Training model...\n",
            "Model trained in 0:00:00.621454\n",
            "Compiling model...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:6 out of the last 6 calls to <function InferenceCoreModel.make_predict_function.<locals>.predict_function_trained at 0x7a937509f240> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model compiled.\n",
            "1/1 [==============================] - 0s 94ms/step\n",
            "1/1 [==============================] - 0s 272ms/step - loss: 0.0000e+00 - accuracy: 0.9268 - binary_crossentropy: 0.2221\n",
            "##### Fold 4\n",
            "Use /tmp/tmp5o5c5n0k as temporary training directory\n",
            "Reading training dataset...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:5 out of the last 5 calls to <function CoreModel._consumes_training_examples_until_eof at 0x7a93e48731a0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training dataset read in 0:00:00.729392. Found 494 examples.\n",
            "Training model...\n",
            "Model trained in 0:00:00.324972\n",
            "Compiling model...\n",
            "Model compiled.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:5 out of the last 5 calls to <function InferenceCoreModel.yggdrasil_model_path_tensor at 0x7a9396763100> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 153ms/step\n",
            "1/1 [==============================] - 0s 437ms/step - loss: 0.0000e+00 - accuracy: 0.9187 - binary_crossentropy: 0.2841\n",
            "##### Fold 5\n",
            "Use /tmp/tmpd_jm2rmh as temporary training directory\n",
            "Reading training dataset...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:6 out of the last 6 calls to <function CoreModel._consumes_training_examples_until_eof at 0x7a93e48731a0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training dataset read in 0:00:01.129618. Found 494 examples.\n",
            "Training model...\n",
            "Model trained in 0:00:00.678359\n",
            "Compiling model...\n",
            "Model compiled.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:6 out of the last 6 calls to <function InferenceCoreModel.yggdrasil_model_path_tensor at 0x7a9375769a80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 95ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:5 out of the last 5 calls to <function InferenceCoreModel.make_test_function.<locals>.test_function at 0x7a937576afc0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 278ms/step - loss: 0.0000e+00 - accuracy: 0.9512 - binary_crossentropy: 0.1557\n",
            "\n",
            "fold_1: acc: 0.9597 loss: 0.1458\n",
            "\n",
            "fold_2: acc: 0.8790 loss: 0.2566\n",
            "\n",
            "fold_3: acc: 0.9268 loss: 0.2221\n",
            "\n",
            "fold_4: acc: 0.9187 loss: 0.2841\n",
            "\n",
            "fold_5: acc: 0.9512 loss: 0.1557\n",
            "\n",
            "Average accuracy: 0.9271  Average loss: 0.2129\n",
            "\n",
            "\n",
            "Precison: 0.8500, Recall: 0.8947, F1 Score: 0.8718\n",
            "\n",
            "Precison: 0.5714, Recall: 0.6667, F1 Score: 0.6154\n",
            "\n",
            "Precison: 0.8462, Recall: 0.8148, F1 Score: 0.8302\n",
            "\n",
            "Precison: 0.7600, Recall: 0.8261, F1 Score: 0.7917\n",
            "\n",
            "Precison: 0.8261, Recall: 0.9048, F1 Score: 0.8636\n",
            "\n",
            "Average Precision: 0.7707  Average Recall: 0.8214, Average F1 Score: 0.7945\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-3.0.1.min.js\"></script>                <div id=\"570fe17f-fb5d-4b17-b940-c78bda6fe485\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                window.PLOTLYENV=window.PLOTLYENV || {};                                if (document.getElementById(\"570fe17f-fb5d-4b17-b940-c78bda6fe485\")) {                    Plotly.newPlot(                        \"570fe17f-fb5d-4b17-b940-c78bda6fe485\",                        [{\"mode\":\"markers+lines\",\"name\":\"Accuracy Fold 1\",\"x\":[1],\"y\":[0.9596773982048035],\"type\":\"scatter\",\"xaxis\":\"x\",\"yaxis\":\"y\"},{\"mode\":\"markers+lines\",\"name\":\"Loss Fold 1\",\"x\":[1],\"y\":[0.14578065276145935],\"type\":\"scatter\",\"xaxis\":\"x2\",\"yaxis\":\"y2\"},{\"mode\":\"markers+lines\",\"name\":\"Precision Fold 1\",\"x\":[1],\"y\":[0.85],\"type\":\"scatter\",\"xaxis\":\"x3\",\"yaxis\":\"y3\"},{\"mode\":\"markers+lines\",\"name\":\"Recall Fold 1\",\"x\":[1],\"y\":[0.8947368421052632],\"type\":\"scatter\",\"xaxis\":\"x4\",\"yaxis\":\"y4\"},{\"mode\":\"markers+lines\",\"name\":\"F1-Score Fold 1\",\"x\":[1],\"y\":[0.8717948717948718],\"type\":\"scatter\",\"xaxis\":\"x5\",\"yaxis\":\"y5\"},{\"mode\":\"markers+lines\",\"name\":\"Accuracy Fold 2\",\"x\":[2],\"y\":[0.8790322542190552],\"type\":\"scatter\",\"xaxis\":\"x\",\"yaxis\":\"y\"},{\"mode\":\"markers+lines\",\"name\":\"Loss Fold 2\",\"x\":[2],\"y\":[0.2566414177417755],\"type\":\"scatter\",\"xaxis\":\"x2\",\"yaxis\":\"y2\"},{\"mode\":\"markers+lines\",\"name\":\"Precision Fold 2\",\"x\":[2],\"y\":[0.5714285714285714],\"type\":\"scatter\",\"xaxis\":\"x3\",\"yaxis\":\"y3\"},{\"mode\":\"markers+lines\",\"name\":\"Recall Fold 2\",\"x\":[2],\"y\":[0.6666666666666666],\"type\":\"scatter\",\"xaxis\":\"x4\",\"yaxis\":\"y4\"},{\"mode\":\"markers+lines\",\"name\":\"F1-Score Fold 2\",\"x\":[2],\"y\":[0.6153846153846154],\"type\":\"scatter\",\"xaxis\":\"x5\",\"yaxis\":\"y5\"},{\"mode\":\"markers+lines\",\"name\":\"Accuracy Fold 3\",\"x\":[3],\"y\":[0.9268292784690857],\"type\":\"scatter\",\"xaxis\":\"x\",\"yaxis\":\"y\"},{\"mode\":\"markers+lines\",\"name\":\"Loss Fold 3\",\"x\":[3],\"y\":[0.2221246361732483],\"type\":\"scatter\",\"xaxis\":\"x2\",\"yaxis\":\"y2\"},{\"mode\":\"markers+lines\",\"name\":\"Precision Fold 3\",\"x\":[3],\"y\":[0.8461538461538461],\"type\":\"scatter\",\"xaxis\":\"x3\",\"yaxis\":\"y3\"},{\"mode\":\"markers+lines\",\"name\":\"Recall Fold 3\",\"x\":[3],\"y\":[0.8148148148148148],\"type\":\"scatter\",\"xaxis\":\"x4\",\"yaxis\":\"y4\"},{\"mode\":\"markers+lines\",\"name\":\"F1-Score Fold 3\",\"x\":[3],\"y\":[0.8301886792452831],\"type\":\"scatter\",\"xaxis\":\"x5\",\"yaxis\":\"y5\"},{\"mode\":\"markers+lines\",\"name\":\"Accuracy Fold 4\",\"x\":[4],\"y\":[0.9186992049217224],\"type\":\"scatter\",\"xaxis\":\"x\",\"yaxis\":\"y\"},{\"mode\":\"markers+lines\",\"name\":\"Loss Fold 4\",\"x\":[4],\"y\":[0.2840743064880371],\"type\":\"scatter\",\"xaxis\":\"x2\",\"yaxis\":\"y2\"},{\"mode\":\"markers+lines\",\"name\":\"Precision Fold 4\",\"x\":[4],\"y\":[0.76],\"type\":\"scatter\",\"xaxis\":\"x3\",\"yaxis\":\"y3\"},{\"mode\":\"markers+lines\",\"name\":\"Recall Fold 4\",\"x\":[4],\"y\":[0.8260869565217391],\"type\":\"scatter\",\"xaxis\":\"x4\",\"yaxis\":\"y4\"},{\"mode\":\"markers+lines\",\"name\":\"F1-Score Fold 4\",\"x\":[4],\"y\":[0.7916666666666666],\"type\":\"scatter\",\"xaxis\":\"x5\",\"yaxis\":\"y5\"},{\"mode\":\"markers+lines\",\"name\":\"Accuracy Fold 5\",\"x\":[5],\"y\":[0.9512194991111755],\"type\":\"scatter\",\"xaxis\":\"x\",\"yaxis\":\"y\"},{\"mode\":\"markers+lines\",\"name\":\"Loss Fold 5\",\"x\":[5],\"y\":[0.1557285189628601],\"type\":\"scatter\",\"xaxis\":\"x2\",\"yaxis\":\"y2\"},{\"mode\":\"markers+lines\",\"name\":\"Precision Fold 5\",\"x\":[5],\"y\":[0.8260869565217391],\"type\":\"scatter\",\"xaxis\":\"x3\",\"yaxis\":\"y3\"},{\"mode\":\"markers+lines\",\"name\":\"Recall Fold 5\",\"x\":[5],\"y\":[0.9047619047619048],\"type\":\"scatter\",\"xaxis\":\"x4\",\"yaxis\":\"y4\"},{\"mode\":\"markers+lines\",\"name\":\"F1-Score Fold 5\",\"x\":[5],\"y\":[0.8636363636363636],\"type\":\"scatter\",\"xaxis\":\"x5\",\"yaxis\":\"y5\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermap\":[{\"type\":\"scattermap\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,1.0]},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.88,1.0]},\"xaxis2\":{\"anchor\":\"y2\",\"domain\":[0.0,1.0]},\"yaxis2\":{\"anchor\":\"x2\",\"domain\":[0.66,0.78]},\"xaxis3\":{\"anchor\":\"y3\",\"domain\":[0.0,1.0]},\"yaxis3\":{\"anchor\":\"x3\",\"domain\":[0.44,0.56],\"title\":{\"text\":\"Value\"}},\"xaxis4\":{\"anchor\":\"y4\",\"domain\":[0.0,1.0]},\"yaxis4\":{\"anchor\":\"x4\",\"domain\":[0.22,0.33999999999999997]},\"xaxis5\":{\"anchor\":\"y5\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"Fold\"}},\"yaxis5\":{\"anchor\":\"x5\",\"domain\":[0.0,0.12]},\"annotations\":[{\"font\":{\"size\":16},\"showarrow\":false,\"text\":\"Accuracy\",\"x\":0.5,\"xanchor\":\"center\",\"xref\":\"paper\",\"y\":1.0,\"yanchor\":\"bottom\",\"yref\":\"paper\"},{\"font\":{\"size\":16},\"showarrow\":false,\"text\":\"Loss\",\"x\":0.5,\"xanchor\":\"center\",\"xref\":\"paper\",\"y\":0.78,\"yanchor\":\"bottom\",\"yref\":\"paper\"},{\"font\":{\"size\":16},\"showarrow\":false,\"text\":\"Precision\",\"x\":0.5,\"xanchor\":\"center\",\"xref\":\"paper\",\"y\":0.56,\"yanchor\":\"bottom\",\"yref\":\"paper\"},{\"font\":{\"size\":16},\"showarrow\":false,\"text\":\"Recall\",\"x\":0.5,\"xanchor\":\"center\",\"xref\":\"paper\",\"y\":0.33999999999999997,\"yanchor\":\"bottom\",\"yref\":\"paper\"},{\"font\":{\"size\":16},\"showarrow\":false,\"text\":\"F1-Score\",\"x\":0.5,\"xanchor\":\"center\",\"xref\":\"paper\",\"y\":0.12,\"yanchor\":\"bottom\",\"yref\":\"paper\"}],\"title\":{\"text\":\"Evaluation Metrics per Fold\"}},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('570fe17f-fb5d-4b17-b940-c78bda6fe485');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Save the Model\n"
      ],
      "metadata": {
        "id": "r9RuWAtX70CI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.save('/content/drive/My Drive/ICR_Project/ICR_model.keras', save_format=\"keras\")"
      ],
      "metadata": {
        "id": "q4Zn0D6M7yh-"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}